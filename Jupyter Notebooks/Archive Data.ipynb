{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import datetime as dt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = SparkSession.builder \\\n",
    "                   .master(\"local[*]\") \\\n",
    "                   .config(\"spark.driver.memory\", \"48g\") \\\n",
    "                   .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.select(\"sensor_type\").distinct().show()\n",
    "\n",
    "all_cols = ['sensor_id',\n",
    "            'sensor_type',\n",
    "            'location',\n",
    "            'lat',\n",
    "            'lon',\n",
    "            'timestamp',\n",
    "            'P1',\n",
    "            'durP1',\n",
    "            'ratioP1',\n",
    "            'P2',\n",
    "            'durP2',\n",
    "            'ratioP2',\n",
    "            'temperature',\n",
    "            'humidity',\n",
    "            'pressure',\n",
    "            'altitude',\n",
    "            'pressure_sealevel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271553357\n"
     ]
    }
   ],
   "source": [
    "dht22_schema = StructType([\n",
    "    StructField(\"sensor_id\", IntegerType()),\n",
    "    StructField(\"sensor_type\", StringType()),\n",
    "    StructField(\"location\", IntegerType()),\n",
    "    StructField(\"lat\", DoubleType()),\n",
    "    StructField(\"lon\", DoubleType()),\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"temperature\", DoubleType()),\n",
    "    StructField(\"humidity\", DoubleType())\n",
    "])\n",
    "dht22_df = sess.read.csv(\"./archive.luftdaten.info/**/*dht22*.csv\", sep=\";\", header=True, schema=dht22_schema) \\\n",
    "               .withColumn(\"pressure\", expr(\"null\").cast(DoubleType())) \\\n",
    "               .withColumn(\"altitude\", expr(\"null\").cast(DoubleType())) \\\n",
    "               .withColumn(\"pressure_sealevel\", expr(\"null\").cast(DoubleType())) \\\n",
    "               .withColumn(\"P1\", expr(\"null\").cast(DoubleType())) \\\n",
    "               .withColumn(\"durP1\", expr(\"null\").cast(DoubleType())) \\\n",
    "               .withColumn(\"ratioP1\", expr(\"null\").cast(DoubleType())) \\\n",
    "               .withColumn(\"P2\", expr(\"null\").cast(DoubleType())) \\\n",
    "               .withColumn(\"durP2\", expr(\"null\").cast(DoubleType())) \\\n",
    "               .withColumn(\"ratioP2\", expr(\"null\").cast(DoubleType())) \n",
    "dht22_df = dht22_df.select(all_cols)\n",
    "print(dht22_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328958478\n"
     ]
    }
   ],
   "source": [
    "sds011_schema = StructType([\n",
    "    StructField(\"sensor_id\", IntegerType()),\n",
    "    StructField(\"sensor_type\", StringType()),\n",
    "    StructField(\"location\", IntegerType()),\n",
    "    StructField(\"lat\", DoubleType()),\n",
    "    StructField(\"lon\", DoubleType()),\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"P1\", DoubleType()),\n",
    "    StructField(\"durP1\", DoubleType()),\n",
    "    StructField(\"ratioP1\", DoubleType()),\n",
    "    StructField(\"P2\", DoubleType()),\n",
    "    StructField(\"durP2\", DoubleType()),\n",
    "    StructField(\"ratioP2\", DoubleType())\n",
    "])\n",
    "sds011_df = sess.read.csv(\"./archive.luftdaten.info/**/*sds011*.csv\", sep=\";\", header=True, schema=sds011_schema) \\\n",
    "                .withColumn(\"temperature\", expr(\"null\")) \\\n",
    "                .withColumn(\"humidity\", expr(\"null\")) \\\n",
    "                .withColumn(\"pressure\", expr(\"null\")) \\\n",
    "                .withColumn(\"altitude\", expr(\"null\")) \\\n",
    "                .withColumn(\"pressure_sealevel\", expr(\"null\"))\n",
    "sds011_df = sds011_df.select(all_cols)\n",
    "print(sds011_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17197116\n"
     ]
    }
   ],
   "source": [
    "ppd42ns_schema =  StructType([\n",
    "    StructField(\"sensor_id\", IntegerType()),\n",
    "    StructField(\"sensor_type\", StringType()),\n",
    "    StructField(\"location\", IntegerType()),\n",
    "    StructField(\"lat\", DoubleType()),\n",
    "    StructField(\"lon\", DoubleType()),\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"P1\", DoubleType()),\n",
    "    StructField(\"durP1\", DoubleType()),\n",
    "    StructField(\"ratioP1\", DoubleType()),\n",
    "    StructField(\"P2\", DoubleType()),\n",
    "    StructField(\"durP2\", DoubleType()),\n",
    "    StructField(\"ratioP2\", DoubleType())\n",
    "])\n",
    "ppd42ns_df = sess.read.csv(\"./archive.luftdaten.info/**/*ppd42ns*.csv\", sep=\";\", header=True, schema=ppd42ns_schema) \\\n",
    "                 .withColumn(\"temperature\", expr(\"null\")) \\\n",
    "                 .withColumn(\"humidity\", expr(\"null\")) \\\n",
    "                 .withColumn(\"pressure\", expr(\"null\")) \\\n",
    "                 .withColumn(\"altitude\", expr(\"null\")) \\\n",
    "                 .withColumn(\"pressure_sealevel\", expr(\"null\"))\n",
    "ppd42ns_df = ppd42ns_df.select(all_cols)\n",
    "print(ppd42ns_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682502\n"
     ]
    }
   ],
   "source": [
    "bmp180_schema =  StructType([\n",
    "    StructField(\"sensor_id\", IntegerType()),\n",
    "    StructField(\"sensor_type\", StringType()),\n",
    "    StructField(\"location\", IntegerType()),\n",
    "    StructField(\"lat\", DoubleType()),\n",
    "    StructField(\"lon\", DoubleType()),\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"pressure\", DoubleType()),\n",
    "    StructField(\"altitude\", DoubleType()),\n",
    "    StructField(\"pressure_sealevel\", DoubleType()),\n",
    "    StructField(\"temperature\", DoubleType())\n",
    "])\n",
    "bmp180_df = sess.read.csv(\"./archive.luftdaten.info/**/*bmp180*.csv\", sep=\";\", header=True, schema=bmp180_schema) \\\n",
    "                .withColumn(\"humidity\", expr(\"null\")) \\\n",
    "                .withColumn(\"P1\", expr(\"null\").cast(DoubleType())) \\\n",
    "                .withColumn(\"durP1\", expr(\"null\").cast(DoubleType())) \\\n",
    "                .withColumn(\"ratioP1\", expr(\"null\").cast(DoubleType())) \\\n",
    "                .withColumn(\"P2\", expr(\"null\").cast(DoubleType())) \\\n",
    "                .withColumn(\"durP2\", expr(\"null\").cast(DoubleType())) \\\n",
    "                .withColumn(\"ratioP2\", expr(\"null\").cast(DoubleType()))\n",
    "bmp180_df = bmp180_df.select(all_cols)\n",
    "print(bmp180_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30079901\n"
     ]
    }
   ],
   "source": [
    "bme280_schema =  StructType([\n",
    "    StructField(\"sensor_id\", IntegerType()),\n",
    "    StructField(\"sensor_type\", StringType()),\n",
    "    StructField(\"location\", IntegerType()),\n",
    "    StructField(\"lat\", DoubleType()),\n",
    "    StructField(\"lon\", DoubleType()),\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"pressure\", DoubleType()),\n",
    "    StructField(\"altitude\", DoubleType()),\n",
    "    StructField(\"pressure_sealevel\", DoubleType()),\n",
    "    StructField(\"temperature\", DoubleType()),\n",
    "    StructField(\"humidity\", DoubleType())\n",
    "])\n",
    "bme280_df = sess.read.csv(\"./archive.luftdaten.info/**/*bme280*.csv\", sep=\";\", header=True, schema=bme280_schema) \\\n",
    "                .withColumn(\"P1\", expr(\"null\").cast(DoubleType())) \\\n",
    "                .withColumn(\"durP1\", expr(\"null\").cast(DoubleType())) \\\n",
    "                .withColumn(\"ratioP1\", expr(\"null\").cast(DoubleType())) \\\n",
    "                .withColumn(\"P2\", expr(\"null\").cast(DoubleType())) \\\n",
    "                .withColumn(\"durP2\", expr(\"null\").cast(DoubleType())) \\\n",
    "                .withColumn(\"ratioP2\", expr(\"null\").cast(DoubleType()))\n",
    "bme280_df = bme280_df.select(all_cols)\n",
    "print(bme280_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649471354"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = dht22_df \\\n",
    "    .unionAll(sds011_df) \\\n",
    "    .unionAll(ppd42ns_df) \\\n",
    "    .unionAll(bmp180_df) \\\n",
    "    .unionAll(bme280_df)\n",
    "all_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sensor_id: integer (nullable = true)\n",
      " |-- sensor_type: string (nullable = true)\n",
      " |-- location: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- P1: double (nullable = true)\n",
      " |-- durP1: double (nullable = true)\n",
      " |-- ratioP1: double (nullable = true)\n",
      " |-- P2: double (nullable = true)\n",
      " |-- durP2: double (nullable = true)\n",
      " |-- ratioP2: double (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- altitude: double (nullable = true)\n",
      " |-- pressure_sealevel: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1749a35c33fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sensor_id = 189\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/apache-spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1688\u001b[0m         \"\"\"\n\u001b[1;32m   1689\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[0;31m##########################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apache-spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \"\"\"\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apache-spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1133\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/apache-spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apache-spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_df.where(\"sensor_id = 189\").orderBy(\"timestamp\").limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"luftdaten.info.%s.parquet\" % dt.date.today().strftime(\"%Y%m%d\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
